\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {1}{\ignorespaces A photorealistic computer generated image using pathtracing.\relax }}{4}{figure.caption.4}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2}{\ignorespaces How radiosity globally illuminates a scene. With each iteration there are more light emitters, meaning that there are more possible patches that can be illuminated. In the first iteration, the only light-emitters are the windows (not visible in the frame). After 16 iterations the scene is sufficiently saturated.\relax }}{4}{figure.caption.5}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3}{\ignorespaces The OpenGL graphics pipeline. The steps within blue boxes are programmable and the ones with dashed borders can be deferred or forwarded.\relax }}{5}{figure.caption.6}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4}{\ignorespaces A scene that was rendered using deferred shading. The objects are locally illuminated by point-lights using g-buffers.\relax }}{6}{figure.caption.7}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {5}{\ignorespaces Example of a albedo-buffer (also called image-buffer). It shows a cornell box with pitch black walls containing two yellow cuboids.\relax }}{6}{figure.caption.8}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {6}{\ignorespaces Example of a z-buffer. The darker a pixel, the further away it is from the cameras point of view.\relax }}{7}{figure.caption.9}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {7}{\ignorespaces Example of a normal-buffer. Normal vectors in this buffer are normalized, meaning their component values range from -1 to 1. Since negative normals would cause negative RGB values, we add $(1, 1, 1)$ and scale with $255/2$, which results in a usable RGB color.\relax }}{7}{figure.caption.10}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {8}{\ignorespaces Diverse visual effects caused by global illumination inside a cornell box. The image was rendered using pathtracing.\relax }}{8}{figure.caption.11}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {9}{\ignorespaces How ambient occlusion affects the realism of a rendered 3d model. The "in-betweens" of the model appear to have depth.\relax }}{9}{figure.caption.12}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {10}{\ignorespaces How a cube-map is rendered. The black sphere in the lower image represents the camera. The resulting six renders are put together in the cube-map in the upper image.\relax }}{10}{figure.caption.13}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {11}{\ignorespaces Depth of field in action. The camera lens is focused on the center sphere, making it appear sharp. The other spheres appear to be blurry.\relax }}{11}{figure.caption.14}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {12}{\ignorespaces An image rendered without (left) and with the usage of 2-layer deep g-buffers (right). The image was generated in 10.8ms at 1080p using NVIDIA GeForce 980, which implies a theoretical framerate of 92 frames per second.\relax }}{15}{figure.caption.15}
